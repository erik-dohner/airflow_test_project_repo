{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GCP credentials found in environment variable: C:\\Users\\edohner\\OneDrive - Lyric Opera of Chicago\\Desktop\\Python Learning\\airflow_test_project\\gcp_service_account.json\n",
      "INFO:root:GCP credentials JSON loaded successfully.\n",
      "INFO:root:Using project ID from JSON credentials: dbt-test-449821\n",
      "INFO:root:Reading sm_raw_responses_string from airflow_raw_source_data...\n",
      "INFO:root:Successfully loaded sm_raw_responses_string from GCP Storage.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from api_library import BQConnect\n",
    "from api_library import StorageConnect\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "from io import StringIO\n",
    "\n",
    "# Grabbing data from blob\n",
    "storage_conn = StorageConnect()\n",
    "\n",
    "try:\n",
    "    \n",
    "    logging.info(f'Reading {storage_conn.sm_raw_responses_blob.name} from {storage_conn.raw_data_bucket.name}...')\n",
    "\n",
    "    # get json string\n",
    "    json_data_string = storage_conn.sm_raw_responses_blob.download_as_text()\n",
    "\n",
    "    responses_data_ls = json.loads(json_data_string)\n",
    "    \n",
    "    logging.info(f'Successfully loaded {storage_conn.sm_raw_responses_blob.name} from GCP Storage.')\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f'Failed to load JSON from GCP Storage: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>choice_metadata.weight</th>\n",
       "      <th>tag_data</th>\n",
       "      <th>text</th>\n",
       "      <th>question_id</th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>collector_id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>date</th>\n",
       "      <th>const_id</th>\n",
       "      <th>email</th>\n",
       "      <th>performance_code</th>\n",
       "      <th>production_name</th>\n",
       "      <th>other_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1492773489</td>\n",
       "      <td>1492773479</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013575</td>\n",
       "      <td>118802733914</td>\n",
       "      <td>459617762</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-17T16:00:03+00:00</td>\n",
       "      <td>516434</td>\n",
       "      <td>nnicketakis@ccim.net</td>\n",
       "      <td>SON02</td>\n",
       "      <td>Sondra Radvanovsky in Concert: The Puccini Her...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1492773508</td>\n",
       "      <td>1492773498</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013576</td>\n",
       "      <td>118802733914</td>\n",
       "      <td>459617762</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-17T16:00:03+00:00</td>\n",
       "      <td>516434</td>\n",
       "      <td>nnicketakis@ccim.net</td>\n",
       "      <td>SON02</td>\n",
       "      <td>Sondra Radvanovsky in Concert: The Puccini Her...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1492773474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013572</td>\n",
       "      <td>118802733914</td>\n",
       "      <td>459617762</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-17T16:00:03+00:00</td>\n",
       "      <td>516434</td>\n",
       "      <td>nnicketakis@ccim.net</td>\n",
       "      <td>SON02</td>\n",
       "      <td>Sondra Radvanovsky in Concert: The Puccini Her...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>It was all good...a truly wonderful evening!</td>\n",
       "      <td>208013573</td>\n",
       "      <td>118802733914</td>\n",
       "      <td>459617762</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-17T16:00:03+00:00</td>\n",
       "      <td>516434</td>\n",
       "      <td>nnicketakis@ccim.net</td>\n",
       "      <td>SON02</td>\n",
       "      <td>Sondra Radvanovsky in Concert: The Puccini Her...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>If there's a recording of this concert, I'd ge...</td>\n",
       "      <td>208013578</td>\n",
       "      <td>118802733914</td>\n",
       "      <td>459617762</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-17T16:00:03+00:00</td>\n",
       "      <td>516434</td>\n",
       "      <td>nnicketakis@ccim.net</td>\n",
       "      <td>SON02</td>\n",
       "      <td>Sondra Radvanovsky in Concert: The Puccini Her...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>The conductor Nicholas Buc was fantastic!  The...</td>\n",
       "      <td>208013573</td>\n",
       "      <td>118804755987</td>\n",
       "      <td>459617692</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-20T00:21:31+00:00</td>\n",
       "      <td>1326141</td>\n",
       "      <td>meowmeow336@yahoo.com</td>\n",
       "      <td>SING</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>My ticket wouldn't open up on my phone. I have...</td>\n",
       "      <td>208013574</td>\n",
       "      <td>118804755987</td>\n",
       "      <td>459617692</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-20T00:21:31+00:00</td>\n",
       "      <td>1326141</td>\n",
       "      <td>meowmeow336@yahoo.com</td>\n",
       "      <td>SING</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1492773532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013584</td>\n",
       "      <td>118804755987</td>\n",
       "      <td>459617692</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-20T00:21:31+00:00</td>\n",
       "      <td>1326141</td>\n",
       "      <td>meowmeow336@yahoo.com</td>\n",
       "      <td>SING</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1492773535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013585</td>\n",
       "      <td>118804755987</td>\n",
       "      <td>459617692</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-20T00:21:31+00:00</td>\n",
       "      <td>1326141</td>\n",
       "      <td>meowmeow336@yahoo.com</td>\n",
       "      <td>SING</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1492773541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208013586</td>\n",
       "      <td>118804755987</td>\n",
       "      <td>459617692</td>\n",
       "      <td>520007028</td>\n",
       "      <td>2025-02-20T00:21:31+00:00</td>\n",
       "      <td>1326141</td>\n",
       "      <td>meowmeow336@yahoo.com</td>\n",
       "      <td>SING</td>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3265 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     choice_id      row_id choice_metadata.weight tag_data  \\\n",
       "0   1492773489  1492773479                    100      NaN   \n",
       "1   1492773508  1492773498                    100      NaN   \n",
       "2   1492773474         NaN                    NaN      NaN   \n",
       "3          NaN         NaN                    NaN       []   \n",
       "4          NaN         NaN                    NaN       []   \n",
       "..         ...         ...                    ...      ...   \n",
       "3          NaN         NaN                    NaN       []   \n",
       "4          NaN         NaN                    NaN       []   \n",
       "5   1492773532         NaN                    NaN      NaN   \n",
       "6   1492773535         NaN                    NaN      NaN   \n",
       "7   1492773541         NaN                    NaN      NaN   \n",
       "\n",
       "                                                 text question_id  \\\n",
       "0                                                 NaN   208013575   \n",
       "1                                                 NaN   208013576   \n",
       "2                                                 NaN   208013572   \n",
       "3        It was all good...a truly wonderful evening!   208013573   \n",
       "4   If there's a recording of this concert, I'd ge...   208013578   \n",
       "..                                                ...         ...   \n",
       "3   The conductor Nicholas Buc was fantastic!  The...   208013573   \n",
       "4   My ticket wouldn't open up on my phone. I have...   208013574   \n",
       "5                                                 NaN   208013584   \n",
       "6                                                 NaN   208013585   \n",
       "7                                                 NaN   208013586   \n",
       "\n",
       "   respondent_id collector_id  survey_id                       date const_id  \\\n",
       "0   118802733914    459617762  520007028  2025-02-17T16:00:03+00:00   516434   \n",
       "1   118802733914    459617762  520007028  2025-02-17T16:00:03+00:00   516434   \n",
       "2   118802733914    459617762  520007028  2025-02-17T16:00:03+00:00   516434   \n",
       "3   118802733914    459617762  520007028  2025-02-17T16:00:03+00:00   516434   \n",
       "4   118802733914    459617762  520007028  2025-02-17T16:00:03+00:00   516434   \n",
       "..           ...          ...        ...                        ...      ...   \n",
       "3   118804755987    459617692  520007028  2025-02-20T00:21:31+00:00  1326141   \n",
       "4   118804755987    459617692  520007028  2025-02-20T00:21:31+00:00  1326141   \n",
       "5   118804755987    459617692  520007028  2025-02-20T00:21:31+00:00  1326141   \n",
       "6   118804755987    459617692  520007028  2025-02-20T00:21:31+00:00  1326141   \n",
       "7   118804755987    459617692  520007028  2025-02-20T00:21:31+00:00  1326141   \n",
       "\n",
       "                    email performance_code  \\\n",
       "0    nnicketakis@ccim.net            SON02   \n",
       "1    nnicketakis@ccim.net            SON02   \n",
       "2    nnicketakis@ccim.net            SON02   \n",
       "3    nnicketakis@ccim.net            SON02   \n",
       "4    nnicketakis@ccim.net            SON02   \n",
       "..                    ...              ...   \n",
       "3   meowmeow336@yahoo.com             SING   \n",
       "4   meowmeow336@yahoo.com             SING   \n",
       "5   meowmeow336@yahoo.com             SING   \n",
       "6   meowmeow336@yahoo.com             SING   \n",
       "7   meowmeow336@yahoo.com             SING   \n",
       "\n",
       "                                      production_name other_id  \n",
       "0   Sondra Radvanovsky in Concert: The Puccini Her...      NaN  \n",
       "1   Sondra Radvanovsky in Concert: The Puccini Her...      NaN  \n",
       "2   Sondra Radvanovsky in Concert: The Puccini Her...      NaN  \n",
       "3   Sondra Radvanovsky in Concert: The Puccini Her...      NaN  \n",
       "4   Sondra Radvanovsky in Concert: The Puccini Her...      NaN  \n",
       "..                                                ...      ...  \n",
       "3                                 Singin' in the Rain      NaN  \n",
       "4                                 Singin' in the Rain      NaN  \n",
       "5                                 Singin' in the Rain      NaN  \n",
       "6                                 Singin' in the Rain      NaN  \n",
       "7                                 Singin' in the Rain      NaN  \n",
       "\n",
       "[3265 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming data\n",
    "    \n",
    "# Initialize list to hold full response dfs as we loop through\n",
    "df_list = []\n",
    "\n",
    "# Normalize the JSON\n",
    "for response_dict in responses_data_ls:\n",
    "    df = pd.json_normalize(response_dict['pages'][0]['questions'], \n",
    "                        record_path=['answers'], \n",
    "                        meta='id',\n",
    "                        meta_prefix='question_'\n",
    "    )\n",
    "        \n",
    "    # Create a dict of col names and their respective values, represented by the dict path in the each answer dict\n",
    "    meta_assignments = {\n",
    "        'respondent_id': 'id',\n",
    "        'collector_id': 'collector_id',\n",
    "        'survey_id': 'survey_id',\n",
    "        'date': 'date_modified',\n",
    "        'const_id': 'custom_variables.customer_no',\n",
    "        'email': 'custom_variables.email',\n",
    "        'performance_code': 'custom_variables.perf',\n",
    "        'production_name': 'custom_variables.prod_name'\n",
    "    }\n",
    "    \n",
    "    # Create function to loop through each level of the specificed values path to find the value at the \n",
    "    # end of that path (as everything else in the path is just dict --> dict -->dict)\n",
    "    def get_nested_path(d, path):\n",
    "        keys = path.split('.')\n",
    "        for key in keys:\n",
    "            d = d.get(key, None) \n",
    "            if not isinstance(d, dict):\n",
    "                break\n",
    "        return d\n",
    "    \n",
    "    # Apply the function to the assignments dict using dict comprehension --> creates new dict\n",
    "    # assign key,values from new dict to existing df\n",
    "    # --> unpacking the dict will return keyword args, formatted as key=value\n",
    "    # --> we can then pass these keyword args to the .assign(**kwargs) as it looking for an indefinit number of keyword args\n",
    "    df = df.assign(**{col: get_nested_path(response_dict, value) for col, value in meta_assignments.items()})\n",
    "\n",
    "    # append this responses data -- now stored in df -- to the df_list to be combined with all responses \n",
    "    df_list.append(df)\n",
    "    \n",
    "# combine all the dfs in the df_list\n",
    "norm_answers = pd.concat(df_list)\n",
    "\n",
    "norm_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully uploaded normalized_data.csv to airflow_raw_source_data.\n"
     ]
    }
   ],
   "source": [
    "# sending to GCP Cloud Storage as csv\n",
    "try:\n",
    "    buffer = StringIO()\n",
    "    norm_answers.to_csv(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    storage_conn.sm_normalized_responses_blob.upload_from_string(buffer.getvalue(), content_type=\"text/csv\")\n",
    "    \n",
    "    logging.info(f\"Successfully uploaded {storage_conn.sm_normalized_responses_blob.name} to {storage_conn.raw_data_bucket.name}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to upload DataFrame to GCS: {e}\")\n",
    "    raise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Retrieved normalized responses csv from blob: normalized_data.csv, project: dbt-test-449821\n"
     ]
    }
   ],
   "source": [
    "# getting the CVS from GCP Storage\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# Initiate the StorageConnect object\n",
    "storage_conn = StorageConnect()\n",
    "\n",
    "# Get normalized.csv\n",
    "try:\n",
    "    normalized_string_data = storage_conn.sm_normalized_responses_blob.download_as_text()\n",
    "    if normalized_string_data:\n",
    "        logging.info(f'Retrieved normalized responses csv from blob: {storage_conn.sm_normalized_responses_blob.name}, project: {storage_conn.project_id}')\n",
    "    else: \n",
    "        raise RuntimeError('Downloaded file is empty')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to retrieve normalized responses CSV from blob: {storage_conn.sm_normalized_responses_blob.name}, project: {storage_conn.project_id}. Error: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:google.cloud.bigquery._pandas_helpers:Error converting Pandas column with name: \"choice_id\" and datatype: \"float64\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Error converting Pandas column with name: \"choice_id\" and datatype: \"float64\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:343\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[1;34m(series, bq_field)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_pandas(series, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39marrow_type)\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError:\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\pyarrow\\array.pxi:1124\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\pyarrow\\array.pxi:358\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowTypeError\u001b[0m: Expected a string or bytes dtype, got float64",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 51\u001b[0m\n\u001b[0;32m     29\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mLoadJobConfig(\n\u001b[0;32m     30\u001b[0m     schema\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     31\u001b[0m         bigquery\u001b[38;5;241m.\u001b[39mSchemaField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoice_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTRING\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     write_disposition\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWRITE_TRUNCATE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# load the table to bigquery\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m load_job \u001b[38;5;241m=\u001b[39m \u001b[43mbq_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalized_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading normalized responses to BigQuery, table: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# wait for the result\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2812\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[1;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[0;32m   2809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parquet_compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnappy\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# adjust the default value\u001b[39;00m\n\u001b[0;32m   2810\u001b[0m         parquet_compression \u001b[38;5;241m=\u001b[39m parquet_compression\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m-> 2812\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtmppath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_use_compliant_nested_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2820\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[0;32m   2821\u001b[0m         tmppath,\n\u001b[0;32m   2822\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2828\u001b[0m         ),\n\u001b[0;32m   2829\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:689\u001b[0m, in \u001b[0;36mdataframe_to_parquet\u001b[1;34m(dataframe, bq_schema, filepath, parquet_compression, parquet_use_compliant_nested_type)\u001b[0m\n\u001b[0;32m    682\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    683\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_compliant_nested_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: parquet_use_compliant_nested_type}\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _versions_helpers\u001b[38;5;241m.\u001b[39mPYARROW_VERSIONS\u001b[38;5;241m.\u001b[39muse_compliant_nested_type\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    688\u001b[0m bq_schema \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m_to_schema_fields(bq_schema)\n\u001b[1;32m--> 689\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mwrite_table(\n\u001b[0;32m    691\u001b[0m     arrow_table,\n\u001b[0;32m    692\u001b[0m     filepath,\n\u001b[0;32m    693\u001b[0m     compression\u001b[38;5;241m=\u001b[39mparquet_compression,\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    695\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:632\u001b[0m, in \u001b[0;36mdataframe_to_arrow\u001b[1;34m(dataframe, bq_schema)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bq_field \u001b[38;5;129;01min\u001b[39;00m bq_schema:\n\u001b[0;32m    630\u001b[0m     arrow_names\u001b[38;5;241m.\u001b[39mappend(bq_field\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    631\u001b[0m     arrow_arrays\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 632\u001b[0m         \u001b[43mbq_to_arrow_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_column_or_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     )\n\u001b[0;32m    634\u001b[0m     arrow_fields\u001b[38;5;241m.\u001b[39mappend(bq_to_arrow_field(bq_field, arrow_arrays[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype))\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m arrow_fields)):\n",
      "File \u001b[1;32mc:\\Users\\edohner\\AppData\\Local\\anaconda3\\envs\\airflow_test\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:347\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[1;34m(series, bq_field)\u001b[0m\n\u001b[0;32m    345\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError converting Pandas column with name: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and datatype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to an appropriate pyarrow datatype: Array, ListArray, or StructArray\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    346\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError(msg)\n",
      "\u001b[1;31mArrowTypeError\u001b[0m: Error converting Pandas column with name: \"choice_id\" and datatype: \"float64\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray"
     ]
    }
   ],
   "source": [
    "# sending the transformed data to bigquery\n",
    "\n",
    "# create dataframe\n",
    "normalized_df = pd.read_csv(StringIO(normalized_string_data))\n",
    "\n",
    "# Initiate the BigQueryConnect object\n",
    "bq_conn = BQConnect()\n",
    "\n",
    "# Fixing datatypes\n",
    "normalized_df['date'] = pd.to_datetime(normalized_df['date'], errors='coerce')\n",
    "\n",
    "str_columns = [ \"choice_id\", \"row_id\", \"choice_metadata.weight\", \"question_id\",\n",
    "    \"respondent_id\", \"collector_id\", \"survey_id\", \"const_id\",\n",
    "    \"email\", \"performance_code\", \"production_name\", \"tag_data\",\n",
    "    \"text\", \"other_id\"]\n",
    "\n",
    "normalized_df[str_columns] = normalized_df[str_columns].astype(str)\n",
    "\n",
    "# define project_id, dataset_id and table_id\n",
    "dataset_id = bq_conn.dataset_pipeline\n",
    "table_id = f'{dataset_id}.raw_sm_responses'\n",
    "\n",
    "# renaming columns\n",
    "normalized_df.rename(columns={\n",
    "    'choice_metadata.weight': 'choice_metadata_weight'\n",
    "}, inplace=True)\n",
    "\n",
    "# configure the specific table we're sending the df to in bigquery\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"choice_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"row_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"choice_metadata_weight\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"question_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"respondent_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"collector_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"survey_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"date\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"const_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"email\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"performance_code\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"production_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"tag_data\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"other_id\", \"STRING\"),\n",
    "    ],\n",
    "    write_disposition=\"WRITE_TRUNCATE\"\n",
    ")\n",
    "\n",
    "# load the table to bigquery\n",
    "load_job = bq_conn.client.load_table_from_dataframe(\n",
    "    normalized_df, table_id, job_config=job_config\n",
    ")\n",
    "\n",
    "logging.info(f'Loading normalized responses to BigQuery, table: {table_id}')\n",
    "\n",
    "# wait for the result\n",
    "load_job.result()  \n",
    "\n",
    "# Check job status and log\n",
    "if load_job.state == 'DONE':\n",
    "    if load_job.error_result:\n",
    "        logging.error(f\"Job failed with error: {load_job.error_result}\")\n",
    "    else:\n",
    "        logging.info(f\"Job completed successfully with {load_job.output_rows} rows loaded.\")\n",
    "else:\n",
    "    logging.warning(f\"Job state: {load_job.state}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
